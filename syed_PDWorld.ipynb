{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "State = namedtuple('State', ['my_i', 'my_j', 'x', 'other_i', 'other_j', 'a', 'b', 'c', 'd', 'e', 'f'])\n",
    "# - i: row index of agent\n",
    "# - j: column index of agent\n",
    "# - x: 1 if agent is carrying a block\n",
    "# - i_distance: distance between the agents' i values\n",
    "# - j_distance: distance between the agents' j values\n",
    "# - a: 1 if pickup location 1 has blocks left\n",
    "# - b: 1 if pickup location 2 has blocks left\n",
    "# - c: 1 if dropoff location 1 has capacity left\n",
    "# - d: 1 if dropoff location 2 has capacity left\n",
    "# - e: 1 if dropoff location 3 has capacity left\n",
    "# - f: 1 if dropoff location 4 has capacity left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDWorld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QTable:\n",
    "    def __init__(self):\n",
    "        self.q_table = np.zeros((world.size**4 * 128, 6))\n",
    "        self.__operator_dict = {'n':0, 's':1, 'e':2, 'w':3, 'p':4, 'd':5}\n",
    "    \n",
    "    def next_operator(self, current_state: State, applicable_operators: list[str], policy: str ='PRANDOM') -> str:\n",
    "        \"\"\"Returns the next operator to be applied given the current state, method, and policy as a string.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        current_state: State\n",
    "            Named tuple containg state information.\n",
    "            - i: row index of agent\n",
    "            - j: column index of agent\n",
    "            - x: 1 if agent is carrying a block\n",
    "            - i_distance: distance between the agents' i values\n",
    "            - j_distance: distance between the agents' j values\n",
    "            - a: 1 if pickup location 1 has blocks left\n",
    "            - b: 1 if pickup location 2 has blocks left\n",
    "            - c: 1 if dropoff location 1 has capacity left\n",
    "            - d: 1 if dropoff location 2 has capacity left\n",
    "            - e: 1 if dropoff location 3 has capacity left\n",
    "            - f: 1 if dropoff location 4 has capacity left\n",
    "\n",
    "        applicable_operators: list\n",
    "            List of applicable operators in the current state\n",
    "        \n",
    "        policy: ['PRANDOM' | 'PEXPLOIT' | 'PGREEDY']\n",
    "            Policy to use when selecting next operator\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "            String corresponding to operator to apply:\n",
    "            ['n' | 's' | 'e' | 'w' | 'p' | 'd']\n",
    "        \"\"\"\n",
    "        assert policy in ['PRANDOM', 'PEXPLOIT', 'PGREEDY'], 'Error: Invalid policy'\n",
    "        next_operator = self.__next_operator(current_state, applicable_operators, policy)\n",
    "        return ['n', 's', 'e', 'w', 'p', 'd'][next_operator]\n",
    "\n",
    "    def update_q_table(self, previous_state: State, operator: str, current_state: State, applicable_operators: list[str], policy: str = 'PRANDOM', method: str = 'QL'):\n",
    "        \"\"\"Updates the Q-table values for the previous state and action used using the given policy and method.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        previous_state: State\n",
    "            Named tuple containg previous state information.\n",
    "            - i: row index of agent\n",
    "            - j: column index of agent\n",
    "            - x: 1 if agent is carrying a block\n",
    "            - i_distance: distance between the agents' i values\n",
    "            - j_distance: distance between the agents' j values\n",
    "            - a: 1 if pickup location 1 has blocks left\n",
    "            - b: 1 if pickup location 2 has blocks left\n",
    "            - c: 1 if dropoff location 1 has capacity left\n",
    "            - d: 1 if dropoff location 2 has capacity left\n",
    "            - e: 1 if dropoff location 3 has capacity left\n",
    "            - f: 1 if dropoff location 4 has capacity left\n",
    "\n",
    "        operator: ['n' | 's' | 'e' | 'w' | 'p' | 'd']\n",
    "            Operator that was used from previous state to current state\n",
    "\n",
    "        current_state: State\n",
    "            Named tuple containg current state information.\n",
    "\n",
    "        applicable_operators: list\n",
    "            List of applicable operators in the current state\n",
    "\n",
    "        policy: ['PRANDOM' | 'PEXPLOIT' | 'PGREEDY']\n",
    "            Policy to use when selecting next operator (used only in SARSA)\n",
    "        \n",
    "        method: ['QL' | 'SARSA']\n",
    "            Method to use when updating Q-table\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            None\n",
    "        \"\"\"\n",
    "        assert method in ['QL', 'SARSA']\n",
    "        \n",
    "        action = self.__operator_dict[operator]\n",
    "        if method == 'SARSA':\n",
    "            self.q_table[self.__encode_state(previous_state), action] = (\n",
    "                self.q_table[self.__encode_state(previous_state), action] +\n",
    "                world.alpha * (world.reward((previous_state.i, previous_state.j), operator) +\n",
    "                world.gamma * self.q_table[self.__encode_state(current_state), self.__next_operator(current_state, policy)] -\n",
    "                self.q_table[self.__encode_state(previous_state), action])\n",
    "            )\n",
    "        elif method == 'QL':\n",
    "            self.q_table[self.__encode_state(previous_state), action] = (\n",
    "                (1 - world.alpha) * self.q_table[self.__encode_state(previous_state), action] + \n",
    "                world.alpha * (world.reward((current_state.i, current_state.j), operator) + \n",
    "                world.gamma * max(self.q_table[self.__encode_state(current_state)][[self.__operator_dict[operator] for operator in applicable_operators]]))\n",
    "            )\n",
    "\n",
    "    def __next_operator(self, current_state: State, applicable_operators: list[str], policy: str ='PRANDOM') -> int:\n",
    "        \"\"\"Returns the next operator to be applied given the current state and policy as an index\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        current_state: State\n",
    "            Named tuple containg state information.\n",
    "\n",
    "        applicable_operators: list\n",
    "            List of applicable operators in the current state\n",
    "\n",
    "        policy: ['PRANDOM' | 'PEXPLOIT' | 'PGREEDY']\n",
    "            Policy to use when selecting next operator\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "            Column index of q-table corresponding to the operator to take\n",
    "            - 0: north\n",
    "            - 1: south\n",
    "            - 2: east\n",
    "            - 3: west\n",
    "            - 4: pick up\n",
    "            - 5: drop off\n",
    "        \"\"\"\n",
    "        applicable_operators_as_indices = [self.__operator_dict[operator] for operator in applicable_operators]\n",
    "        if 4 in applicable_operators_as_indices:\n",
    "            return 4\n",
    "        if 5 in applicable_operators_as_indices:\n",
    "            return 5\n",
    "        else:\n",
    "            max_val_operators = np.flatnonzero(self.q_table[self.__encode_state(current_state)] == np.max(self.q_table[self.__encode_state(current_state)]))\n",
    "            if policy == 'PRANDOM':\n",
    "                # select applicable operator randomly\n",
    "                return np.random.choice(applicable_operators_as_indices)\n",
    "            elif policy == 'PEXPLOIT':\n",
    "                if np.random.rand() < 0.8:\n",
    "                    # select applicable operator with highest q-value\n",
    "                    return np.random.choice(max_val_operators)\n",
    "                else:\n",
    "                    # select applicable operator randomly from operators without highest q-value\n",
    "                    return np.random.choice(np.setdiff1d(applicable_operators_as_indices, max_val_operators))\n",
    "            elif policy == 'PGREEDY':\n",
    "                # select applicable operator with highest q-value\n",
    "                return np.random.choice(max_val_operators)\n",
    "\n",
    "    def __encode_state(state: State) -> int:\n",
    "        \"\"\"Encodes the given state into its row index in the Q-table\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        state : State\n",
    "            Named tuple containing state information\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            integer index of state in Q-table\n",
    "        \"\"\"\n",
    "        multipliers = np.array([world.size**3 * 128, world.size**2 * 128, world.size**2 * 64, world.size * 64, 64, 32, 16, 8, 4, 2, 1])\n",
    "        return np.sum(np.multiply(np.array(state), multipliers))\n",
    "    \n",
    "    def __decode_index(index: int) -> State:\n",
    "        \"\"\"Decodes the given row index of the Q-table into a State named tuple\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        index : int\n",
    "            Row index of the Q-table\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "            Named tuple containing state information\n",
    "        \"\"\"\n",
    "        state_values = []\n",
    "        divisors = [world.size**3 * 128, world.size**2 * 128, world.size**2 * 64, world.size * 64, 64, 32, 16, 8, 4, 2, 1]\n",
    "        remainder = index\n",
    "        for divisor in divisors:\n",
    "            state_values.append(int(np.floor(remainder / divisor)))\n",
    "            remainder = remainder % divisor\n",
    "        return State(*state_values)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, q_table_obj, agent=\"F\"):\n",
    "        self.identifier = agent\n",
    "        self.carrying_block = False\n",
    "        self.q_table = QTable()\n",
    "\n",
    "        # Female agent starts at (1,3) in non-index position, male starts at (5,3)\n",
    "        self.i = 0 if agent == \"F\" else 4\n",
    "        self.j = 2 if agent == \"F\" else 2\n",
    "        self.i_other_agent = 4 if agent == \"F\" else 0\n",
    "        self.j_other_agent = 2 if agent == \"F\" else 2\n",
    "    \n",
    "    def update_position(self, new_i: int, new_j: int):\n",
    "        self.i = new_i\n",
    "        self.j = new_j\n",
    "    \n",
    "    def update_other_agent_position(self, new_i: int, new_j: int):\n",
    "        self.i_other_agent = new_i\n",
    "        self.j_other_agent = new_j\n",
    "    \n",
    "    def get_distance_to_other_agent(self):\n",
    "        return (abs(self.i - self.i_other_agent), abs(self.j - self.j_other_agent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDWorld:\n",
    "    def __init__(self, size, alpha, gamma, pickup_capacity, dropoff_capacity, pickup_locations, dropoff_locations):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            - size = 5,\n",
    "            - alpha = 0.3,\n",
    "            - gamma = 0.5,\n",
    "            - pickup_capacity = 10,\n",
    "            - dropoff_capacity = 5,\n",
    "            - agent_start_locations = [(1,3), (5,3)],\n",
    "            - pickup_locations = [(3,5), (4,2)],\n",
    "            - dropoff_locations = [(1,1), (1,5), (3,3), (5,5)])\n",
    "        \"\"\"\n",
    "\n",
    "        self.board = np.zeros((size,size))\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.dropoff_capacity = dropoff_capacity\n",
    "        self.female_agent = Agent(None, agent=\"F\")  # ToDo: give qtable\n",
    "        self.male_agent = Agent(None, agent=\"F\")  # ToDo: give qtable\n",
    "        self.iteration = 0\n",
    "        self.turn = 0  # 0 if female agent's turn, 1 otherwise\n",
    "\n",
    "        self.dropoff_locations = {\n",
    "            (0,0): 0, \n",
    "            (0,4): 0, \n",
    "            (2,2): 0, \n",
    "            (4,4): 0\n",
    "        }\n",
    "        self.pickup_locations = {\n",
    "            (2,4): pickup_capacity, \n",
    "            (3,1): pickup_capacity\n",
    "        }\n",
    "    \n",
    "    def setup(self, size: int, pickup_locations: list = None, dropoff_locations: list = None):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        - size: size of square board\n",
    "        - pickup_locations: list of tuples (i,j) of pickup locations\n",
    "        - dropoff_locations: list of tuples (i,j) of dropoff locations\n",
    "        \"\"\"\n",
    "        self.size = size\n",
    "        self.board = np.zeros((size, size))\n",
    "\n",
    "        if pickup_locations:\n",
    "            self.pickup_locations.clear()\n",
    "            for tup in pickup_locations:\n",
    "                self.pickup_locations[tup] = 10\n",
    "        \n",
    "        if dropoff_locations:\n",
    "            self.dropoff_locations.clear()\n",
    "            for tup in dropoff_locations:\n",
    "                self.dropoff_locations[tup] = 0\n",
    "    \n",
    "    def applicable_operators(self, agent):\n",
    "        applicable_ops = [\"n\", \"s\", \"e\", \"w\"]  # \"p\" and \"d\" are appended if conditions are met\n",
    "\n",
    "        if agent.i == self.board.shape[1] or agent.i_other_agent == agent.i + 1:\n",
    "            applicable_ops.remove(\"s\")\n",
    "        \n",
    "        if agent.i == 0 or agent.i_other_agent == agent.i - 1:\n",
    "            applicable_ops.remove(\"n\")\n",
    "\n",
    "        if agent.j == self.board.shape[0] or agent.j_other_agent == agent.j + 1:\n",
    "            applicable_ops.remove(\"e\")\n",
    "\n",
    "        if agent.j == 0 or agent.j_other_agent == agent.j - 1:\n",
    "            applicable_ops.remove(\"w\")\n",
    "        \n",
    "        for loc, block_count in self.dropoff_locations.items():\n",
    "            if agent.carrying_block and block_count < self.dropoff_capacity and \\\n",
    "                agent.i == loc[0] and agent.j == loc[1]:\n",
    "                applicable_ops.append(\"d\")\n",
    "    \n",
    "        for loc, block_count in self.pickup_locations.items():\n",
    "            if not agent.carrying_block and block_count > 0 and \\\n",
    "                agent.i == loc[0] and agent.j == loc[1]:\n",
    "                applicable_ops.append(\"p\")\n",
    "    \n",
    "    def apply_operator(self, agent, other_agent, operator):\n",
    "        assert operator in [\"n\", \"s\", \"e\", \"w\", \"d\", \"p\"], \"Error: Unknown Operator\"\n",
    "\n",
    "        if operator == \"n\":\n",
    "            agent.update_position(agent.i - 1, agent.j)\n",
    "            other_agent.update_other_agent_position(agent.i, agent.j)\n",
    "        elif operator == \"s\":\n",
    "            agent.update_position(agent.i + 1, agent.j)\n",
    "            other_agent.update_other_agent_position(agent.i, agent.j)\n",
    "        elif operator == \"e\":\n",
    "            agent.update_position(agent.i, agent.j + 1)\n",
    "            other_agent.update_other_agent_position(agent.i, agent.j)\n",
    "        elif operator == \"w\":\n",
    "            agent.update_position(agent.i, agent.j - 1)\n",
    "            other_agent.update_other_agent_position(agent.i, agent.j)\n",
    "        elif operator == \"d\":\n",
    "            agent.carrying_block = False\n",
    "            loc_tup = (agent.i, agent.j)\n",
    "            self.dropoff_locations[loc_tup] += 1\n",
    "        elif operator == \"p\":\n",
    "            agent.carrying_block = True\n",
    "            loc_tup = (agent.i, agent.j)\n",
    "            self.pickup_locations[loc_tup] -= 1\n",
    "    \n",
    "    def run(self, steps=500, policy='PRANDOM', method='SARSA'):\n",
    "        for iter in range(steps):\n",
    "            ##########################\n",
    "            # Female agent making move\n",
    "            ##########################\n",
    "            # Get applicable operators given current state\n",
    "            F_applicable_operators = self.applicable_operators(self.female_agent)\n",
    "            # Compute current state named tuple\n",
    "            curr_state = self._compute_current_state()\n",
    "            # Use QTable function to get next operator based on current state, policy, and method\n",
    "            next_op = self.female_agent.q_table.next_operator(curr_state, F_applicable_operators, policy=policy)\n",
    "            # Apply operator to current state and female agent\n",
    "            self.apply_operator(self.female_agent, self.male_agent, next_op)\n",
    "            updated_state = self._compute_current_state()\n",
    "\n",
    "            # Update female agent QTable\n",
    "            self.female_agent.q_table.update_q_table(\n",
    "                previous_state=curr_state, \n",
    "                operator=next_op, \n",
    "                current_state=updated_state, \n",
    "                applicable_operators=F_applicable_operators, \n",
    "                policy=policy, \n",
    "                method=method)\n",
    "            \n",
    "            ##########################\n",
    "            # Male agent making move\n",
    "            ##########################\n",
    "            # Get applicable operators given current state\n",
    "            M_applicable_operators = self.applicable_operators(self.male_agent)\n",
    "            # Compute current state named tuple\n",
    "            M_curr_state = self._compute_current_state()\n",
    "            # Use QTable function to get next operator based on current state, policy, and method\n",
    "            next_op = self.male_agent.q_table.next_operator(M_curr_state, M_applicable_operators, policy=policy)\n",
    "            # Apply operator to current state and female agent\n",
    "            self.apply_operator(self.male_agent, self.female_agent, next_op)\n",
    "            M_updated_state = self._compute_current_state()\n",
    "\n",
    "            # Update male agent QTable\n",
    "            self.male_agent.q_table.update_q_table(\n",
    "                previous_state=M_curr_state, \n",
    "                operator=next_op, \n",
    "                current_state=M_updated_state, \n",
    "                applicable_operators=M_applicable_operators, \n",
    "                policy=policy, \n",
    "                method=method)\n",
    "            \n",
    "            self.iteration += 1\n",
    "    \n",
    "    def _compute_current_state(self):\n",
    "        distance_tuple = self.female_agent.get_distance_to_other_agent()\n",
    "        pickup_flags = [1 if block_count > 0 else 0 for _, block_count in self.dropoff_locations.items()]\n",
    "        dropoff_flags = [1 if block_count < self.dropoff_capacity else 0 for _, block_count in self.dropoff_locations.items()]\n",
    "\n",
    "        curr_state = State(\n",
    "            self.female_agent.i, \n",
    "            self.female_agent.j, \n",
    "            int(self.female_agent.carrying_block), \n",
    "            distance_tuple[0],\n",
    "            distance_tuple[1],\n",
    "            pickup_flags[0],\n",
    "            pickup_flags[1],\n",
    "            dropoff_flags[0],\n",
    "            dropoff_flags[1],\n",
    "            dropoff_flags[2],\n",
    "            dropoff_flags[3]\n",
    "        )\n",
    "        return curr_state\n",
    "        \n",
    "    def change_pickup_location(self, new_pickup_locations: list[tuple]):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        - new_pickup_locations: list of tuples (i,j) of new pickup locations on board\n",
    "        \"\"\"\n",
    "        self.pickup_locations.clear()\n",
    "        for tup in new_pickup_locations:\n",
    "                self.pickup_locations[tup] = 10\n",
    "\n",
    "    def save_visual_midrun():\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Driver Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global PDWorld object\n",
    "world = PDWorld()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to run experiments\n",
    "def experiment_1a():\n",
    "    world.setup(size = 5,\n",
    "                alpha = 0.3,\n",
    "                gamma = 0.5,\n",
    "                pickup_capacity = 10,\n",
    "                dropoff_capacity = 5,\n",
    "                agent_start_locations = [(1,3), (5,3)],\n",
    "                pickup_locations = [(3,5), (4,2)],\n",
    "                dropoff_locations = [(1,1), (1,5), (3,3), (5,5)])\n",
    "    world.run(steps=500, policy='PRANDOM')\n",
    "    world.run(steps=7500, policy='PRANDOM')\n",
    "    world.summary()\n",
    "\n",
    "def experiment_1b():\n",
    "    world.setup(size = 5,\n",
    "                alpha = 0.3,\n",
    "                gamma = 0.5,\n",
    "                pickup_capacity = 10,\n",
    "                dropoff_capacity = 5,\n",
    "                agent_start_locations = [(1,3), (5,3)],\n",
    "                pickup_locations = [(3,5), (4,2)],\n",
    "                dropoff_locations = [(1,1), (1,5), (3,3), (5,5)])\n",
    "    world.run(steps=500, policy='PRANDOM')\n",
    "    world.run(steps=7500, policy='PGREEDY')\n",
    "    world.summary()\n",
    "\n",
    "def experiment_1c():\n",
    "    world.setup(size = 5,\n",
    "                alpha = 0.3,\n",
    "                gamma = 0.5,\n",
    "                pickup_capacity = 10,\n",
    "                dropoff_capacity = 5,\n",
    "                agent_start_locations = [(1,3), (5,3)],\n",
    "                pickup_locations = [(3,5), (4,2)],\n",
    "                dropoff_locations = [(1,1), (1,5), (3,3), (5,5)])\n",
    "    world.run(steps=500, policy='PRANDOM')\n",
    "    world.run(steps=7500, policy='PEXPLOIT')\n",
    "    world.summary()\n",
    "    world.display_q_table(agent='male')\n",
    "\n",
    "def experiment_2():\n",
    "    world.setup(size = 5,\n",
    "                alpha = 0.3,\n",
    "                gamma = 0.5,\n",
    "                pickup_capacity = 10,\n",
    "                dropoff_capacity = 5,\n",
    "                agent_start_locations = [(1,3), (5,3)],\n",
    "                pickup_locations = [(3,5), (4,2)],\n",
    "                dropoff_locations = [(1,1), (1,5), (3,3), (5,5)])\n",
    "    world.run(steps=500, policy='PRANDOM', method='SARSA')\n",
    "    world.run(steps=7500, policy='PEXPLOIT', method='SARSA')\n",
    "    world.summary()\n",
    "    world.display_q_table(agent='male')\n",
    "\n",
    "def experiment_3a():\n",
    "    world.setup(size = 5,\n",
    "                alpha = 0.15,\n",
    "                gamma = 0.5,\n",
    "                pickup_capacity = 10,\n",
    "                dropoff_capacity = 5,\n",
    "                agent_start_locations = [(1,3), (5,3)],\n",
    "                pickup_locations = [(3,5), (4,2)],\n",
    "                dropoff_locations = [(1,1), (1,5), (3,3), (5,5)])\n",
    "    world.run(steps=500, policy='PRANDOM')\n",
    "    world.run(steps=7500, policy='PEXPLOIT')\n",
    "    world.summary()\n",
    "    world.display_q_table(agent='male')\n",
    "\n",
    "def experiment_3b():\n",
    "    world.setup(size = 5,\n",
    "                alpha = 0.45,\n",
    "                gamma = 0.5,\n",
    "                pickup_capacity = 10,\n",
    "                dropoff_capacity = 5,\n",
    "                agent_start_locations = [(1,3), (5,3)],\n",
    "                pickup_locations = [(3,5), (4,2)],\n",
    "                dropoff_locations = [(1,1), (1,5), (3,3), (5,5)])\n",
    "    world.run(steps=500, policy='PRANDOM')\n",
    "    world.run(steps=7500, policy='PEXPLOIT')\n",
    "    world.summary()\n",
    "    world.display_q_table(agent='male')\n",
    "\n",
    "def experiment_4():\n",
    "    world.setup(size = 5,\n",
    "                alpha = 0.3,\n",
    "                gamma = 0.5,\n",
    "                pickup_capacity = 10,\n",
    "                dropoff_capacity = 5,\n",
    "                agent_start_locations = [(1,3), (5,3)],\n",
    "                pickup_locations = [(3,5), (4,2)],\n",
    "                dropoff_locations = [(1,1), (1,5), (3,3), (5,5)])\n",
    "    world.run(steps=500, policy='PRANDOM')\n",
    "    world.run(total_runs=3, policy='PEXPLOIT', animate=True)\n",
    "    world.summary()\n",
    "    world.display_q_table(agent='male')\n",
    "    \n",
    "    world.setup(pickup_locations = [(1,2), (4,5)])\n",
    "    world.run(total_runs=3, policy='PEXPLOIT', animate=True)\n",
    "    world.summary()\n",
    "    world.display_q_table(agent='male')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
