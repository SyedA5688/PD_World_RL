{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "State = namedtuple('State', \n",
    "                   ['my_i', 'my_j', 'x', 'other_i', 'other_j', 'a', 'b', 'c', 'd', 'e', 'f'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PDWorld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDWorld:\n",
    "    def __init__(self):\n",
    "        self.size = 5\n",
    "        self.alpha = 0.3,\n",
    "        self.gamma = 0.5,\n",
    "        self.pickup_locations = [(3,5), (4,2)]\n",
    "        self.dropoff_locations = [(1,1), (1,5), (3,3), (5,5)]\n",
    "        self.board = np.zeros((self.size, self.size))\n",
    "\n",
    "    def setup(self, size: int, alpha: float, gamma: float, pickup_locations: list, dropoff_locations: list):\n",
    "        if size:\n",
    "            self.size = size\n",
    "            self.board = np.zeros((size, size))\n",
    "        if alpha:\n",
    "            self.alpha = alpha\n",
    "        if gamma:\n",
    "            self.gamma = gamma\n",
    "        if pickup_locations:\n",
    "            self.pickup_locations = pickup_locations\n",
    "        if dropoff_locations:\n",
    "            self.dropoff_locations = dropoff_locations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global PDWorld object\n",
    "world = PDWorld()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to run experiments\n",
    "def experiment_1a():\n",
    "    world.setup(size = 5,\n",
    "                alpha = 0.3,\n",
    "                gamma = 0.5,\n",
    "                pickup_capacity = 10,\n",
    "                dropoff_capacity = 5,\n",
    "                agent_start_locations = [(1,3), (5,3)],\n",
    "                pickup_locations = [(3,5), (4,2)],\n",
    "                dropoff_locations = [(1,1), (1,5), (3,3), (5,5)])\n",
    "    world.run(steps=500, policy='PRANDOM')\n",
    "    world.run(steps=7500, policy='PRANDOM')\n",
    "    world.summary()\n",
    "\n",
    "def experiment_1b():\n",
    "    world.setup(size = 5,\n",
    "                alpha = 0.3,\n",
    "                gamma = 0.5,\n",
    "                pickup_capacity = 10,\n",
    "                dropoff_capacity = 5,\n",
    "                agent_start_locations = [(1,3), (5,3)],\n",
    "                pickup_locations = [(3,5), (4,2)],\n",
    "                dropoff_locations = [(1,1), (1,5), (3,3), (5,5)])\n",
    "    world.run(steps=500, policy='PRANDOM')\n",
    "    world.run(steps=7500, policy='PGREEDY')\n",
    "    world.summary()\n",
    "\n",
    "def experiment_1c():\n",
    "    world.setup(size = 5,\n",
    "                alpha = 0.3,\n",
    "                gamma = 0.5,\n",
    "                pickup_capacity = 10,\n",
    "                dropoff_capacity = 5,\n",
    "                agent_start_locations = [(1,3), (5,3)],\n",
    "                pickup_locations = [(3,5), (4,2)],\n",
    "                dropoff_locations = [(1,1), (1,5), (3,3), (5,5)])\n",
    "    world.run(steps=500, policy='PRANDOM')\n",
    "    world.run(steps=7500, policy='PEXPLOIT')\n",
    "    world.summary()\n",
    "    world.display_q_table(agent='male')\n",
    "\n",
    "def experiment_2():\n",
    "    world.setup(size = 5,\n",
    "                alpha = 0.3,\n",
    "                gamma = 0.5,\n",
    "                pickup_capacity = 10,\n",
    "                dropoff_capacity = 5,\n",
    "                agent_start_locations = [(1,3), (5,3)],\n",
    "                pickup_locations = [(3,5), (4,2)],\n",
    "                dropoff_locations = [(1,1), (1,5), (3,3), (5,5)])\n",
    "    world.run(steps=500, policy='PRANDOM', method='SARSA')\n",
    "    world.run(steps=7500, policy='PEXPLOIT', method='SARSA')\n",
    "    world.summary()\n",
    "    world.display_q_table(agent='male')\n",
    "\n",
    "def experiment_3a():\n",
    "    world.setup(size = 5,\n",
    "                alpha = 0.15,\n",
    "                gamma = 0.5,\n",
    "                pickup_capacity = 10,\n",
    "                dropoff_capacity = 5,\n",
    "                agent_start_locations = [(1,3), (5,3)],\n",
    "                pickup_locations = [(3,5), (4,2)],\n",
    "                dropoff_locations = [(1,1), (1,5), (3,3), (5,5)])\n",
    "    world.run(steps=500, policy='PRANDOM')\n",
    "    world.run(steps=7500, policy='PEXPLOIT')\n",
    "    world.summary()\n",
    "    world.display_q_table(agent='male')\n",
    "\n",
    "def experiment_3b():\n",
    "    world.setup(size = 5,\n",
    "                alpha = 0.45,\n",
    "                gamma = 0.5,\n",
    "                pickup_capacity = 10,\n",
    "                dropoff_capacity = 5,\n",
    "                agent_start_locations = [(1,3), (5,3)],\n",
    "                pickup_locations = [(3,5), (4,2)],\n",
    "                dropoff_locations = [(1,1), (1,5), (3,3), (5,5)])\n",
    "    world.run(steps=500, policy='PRANDOM')\n",
    "    world.run(steps=7500, policy='PEXPLOIT')\n",
    "    world.summary()\n",
    "    world.display_q_table(agent='male')\n",
    "\n",
    "def experiment_4():\n",
    "    world.setup(size = 5,\n",
    "                alpha = 0.3,\n",
    "                gamma = 0.5,\n",
    "                pickup_capacity = 10,\n",
    "                dropoff_capacity = 5,\n",
    "                agent_start_locations = [(1,3), (5,3)],\n",
    "                pickup_locations = [(3,5), (4,2)],\n",
    "                dropoff_locations = [(1,1), (1,5), (3,3), (5,5)])\n",
    "    world.run(steps=500, policy='PRANDOM')\n",
    "    world.run(total_runs=3, policy='PEXPLOIT', animate=True)\n",
    "    world.summary()\n",
    "    world.display_q_table(agent='male')\n",
    "    \n",
    "    world.setup(pickup_locations = [(1,2), (4,5)])\n",
    "    world.run(total_runs=3, policy='PEXPLOIT', animate=True)\n",
    "    world.summary()\n",
    "    world.display_q_table(agent='male')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q-Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QTable:\n",
    "    def __init__(self):\n",
    "        self.q_table = np.zeros((world.size**4 * 2**7 ,6))\n",
    "    \n",
    "    def _encode_state(state: State) -> int:\n",
    "        \"\"\"Encodes the given state into its row index in the Q-table\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        state : State\n",
    "            Named tuple containing state information\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            integer index of state in Q-table\n",
    "        \"\"\"\n",
    "        return (\n",
    "            state.my_i * world.size**3 * 2**7 +\n",
    "            state.my_j * world.size**2 * 2**7 +\n",
    "            state.x * world.size**2 * 2**6 +\n",
    "            state.other_i * world.size * 2**6 +\n",
    "            state.other_j * 2**6 +\n",
    "            state.a * 2**5 +\n",
    "            state.b * 2**4 +\n",
    "            state.c * 2**3 +\n",
    "            state.d * 2**2 +\n",
    "            state.e * 2 +\n",
    "            state.f)\n",
    "    \n",
    "    def next_operator(current_state: State, method: str = 'QL', policy: str ='PRANDOM'):\n",
    "        applicable_operators = world.applicable_operators(current_state)\n",
    "\n",
    "        pass\n",
    "\n",
    "    def _update_q_table(self, current_state: State, action: int, next_state: State, method: str = 'QL'):\n",
    "        if method == 'SARSA':\n",
    "            self.q_table[self._encode_state(current_state), action] = (\n",
    "                \n",
    "            )\n",
    "        else:\n",
    "            self.q_table[self._encode_state(current_state), action] = (\n",
    "                (1 - world.alpha) * self.q_table[self._encode_state(current_state), action] + \n",
    "                world.alpha * ((world.penalty if action < 4 else world.reward) + \n",
    "                world.gamma * self.q_table[self._encode_state(next_state), max(world.applicable_operators(next_state))])\n",
    "            )\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cef9e06bb236b2a8629b07e87a04b187b952a0f661eff5533360a155783f0c33"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
