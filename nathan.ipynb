{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - i: row index of agent\n",
    "# - j: column index of agent\n",
    "# - x: 1 if agent is carrying a block\n",
    "# - i_distance: distance between the agents' i values\n",
    "# - j_distance: distance between the agents' j values\n",
    "# - a: 1 if pickup location 1 has blocks left\n",
    "# - b: 1 if pickup location 2 has blocks left\n",
    "# - c: 1 if dropoff location 1 has capacity left\n",
    "# - d: 1 if dropoff location 2 has capacity left\n",
    "# - e: 1 if dropoff location 3 has capacity left\n",
    "# - f: 1 if dropoff location 4 has capacity left\n",
    "State = namedtuple('State', \n",
    "                   ['i', 'j', 'x', 'i_distance', 'j_distance', 'a', 'b', 'c', 'd', 'e', 'f'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PDWorld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDWorld:\n",
    "    def __init__(self):\n",
    "        self.size = 5\n",
    "        self.alpha = 0.3,\n",
    "        self.gamma = 0.5,\n",
    "        self.pickup_locations = [(3,5), (4,2)]\n",
    "        self.dropoff_locations = [(1,1), (1,5), (3,3), (5,5)]\n",
    "        self.board = np.zeros((self.size, self.size))\n",
    "\n",
    "    def setup(self, size: int, alpha: float, gamma: float, pickup_locations: list, dropoff_locations: list):\n",
    "        if size:\n",
    "            self.size = size\n",
    "            self.board = np.zeros((size, size))\n",
    "        if alpha:\n",
    "            self.alpha = alpha\n",
    "        if gamma:\n",
    "            self.gamma = gamma\n",
    "        if pickup_locations:\n",
    "            self.pickup_locations = pickup_locations\n",
    "        if dropoff_locations:\n",
    "            self.dropoff_locations = dropoff_locations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global PDWorld object\n",
    "world = PDWorld()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to run experiments\n",
    "def experiment_1a():\n",
    "    world.setup(size = 5,\n",
    "                alpha = 0.3,\n",
    "                gamma = 0.5,\n",
    "                pickup_capacity = 10,\n",
    "                dropoff_capacity = 5,\n",
    "                agent_start_locations = [(1,3), (5,3)],\n",
    "                pickup_locations = [(3,5), (4,2)],\n",
    "                dropoff_locations = [(1,1), (1,5), (3,3), (5,5)])\n",
    "    world.run(steps=500, policy='PRANDOM')\n",
    "    world.run(steps=7500, policy='PRANDOM')\n",
    "    world.summary()\n",
    "\n",
    "def experiment_1b():\n",
    "    world.setup(size = 5,\n",
    "                alpha = 0.3,\n",
    "                gamma = 0.5,\n",
    "                pickup_capacity = 10,\n",
    "                dropoff_capacity = 5,\n",
    "                agent_start_locations = [(1,3), (5,3)],\n",
    "                pickup_locations = [(3,5), (4,2)],\n",
    "                dropoff_locations = [(1,1), (1,5), (3,3), (5,5)])\n",
    "    world.run(steps=500, policy='PRANDOM')\n",
    "    world.run(steps=7500, policy='PGREEDY')\n",
    "    world.summary()\n",
    "\n",
    "def experiment_1c():\n",
    "    world.setup(size = 5,\n",
    "                alpha = 0.3,\n",
    "                gamma = 0.5,\n",
    "                pickup_capacity = 10,\n",
    "                dropoff_capacity = 5,\n",
    "                agent_start_locations = [(1,3), (5,3)],\n",
    "                pickup_locations = [(3,5), (4,2)],\n",
    "                dropoff_locations = [(1,1), (1,5), (3,3), (5,5)])\n",
    "    world.run(steps=500, policy='PRANDOM')\n",
    "    world.run(steps=7500, policy='PEXPLOIT')\n",
    "    world.summary()\n",
    "    world.display_q_table(agent='male')\n",
    "\n",
    "def experiment_2():\n",
    "    world.setup(size = 5,\n",
    "                alpha = 0.3,\n",
    "                gamma = 0.5,\n",
    "                pickup_capacity = 10,\n",
    "                dropoff_capacity = 5,\n",
    "                agent_start_locations = [(1,3), (5,3)],\n",
    "                pickup_locations = [(3,5), (4,2)],\n",
    "                dropoff_locations = [(1,1), (1,5), (3,3), (5,5)])\n",
    "    world.run(steps=500, policy='PRANDOM', method='SARSA')\n",
    "    world.run(steps=7500, policy='PEXPLOIT', method='SARSA')\n",
    "    world.summary()\n",
    "    world.display_q_table(agent='male')\n",
    "\n",
    "def experiment_3a():\n",
    "    world.setup(size = 5,\n",
    "                alpha = 0.15,\n",
    "                gamma = 0.5,\n",
    "                pickup_capacity = 10,\n",
    "                dropoff_capacity = 5,\n",
    "                agent_start_locations = [(1,3), (5,3)],\n",
    "                pickup_locations = [(3,5), (4,2)],\n",
    "                dropoff_locations = [(1,1), (1,5), (3,3), (5,5)])\n",
    "    world.run(steps=500, policy='PRANDOM')\n",
    "    world.run(steps=7500, policy='PEXPLOIT')\n",
    "    world.summary()\n",
    "    world.display_q_table(agent='male')\n",
    "\n",
    "def experiment_3b():\n",
    "    world.setup(size = 5,\n",
    "                alpha = 0.45,\n",
    "                gamma = 0.5,\n",
    "                pickup_capacity = 10,\n",
    "                dropoff_capacity = 5,\n",
    "                agent_start_locations = [(1,3), (5,3)],\n",
    "                pickup_locations = [(3,5), (4,2)],\n",
    "                dropoff_locations = [(1,1), (1,5), (3,3), (5,5)])\n",
    "    world.run(steps=500, policy='PRANDOM')\n",
    "    world.run(steps=7500, policy='PEXPLOIT')\n",
    "    world.summary()\n",
    "    world.display_q_table(agent='male')\n",
    "\n",
    "def experiment_4():\n",
    "    world.setup(size = 5,\n",
    "                alpha = 0.3,\n",
    "                gamma = 0.5,\n",
    "                pickup_capacity = 10,\n",
    "                dropoff_capacity = 5,\n",
    "                agent_start_locations = [(1,3), (5,3)],\n",
    "                pickup_locations = [(3,5), (4,2)],\n",
    "                dropoff_locations = [(1,1), (1,5), (3,3), (5,5)])\n",
    "    world.run(steps=500, policy='PRANDOM')\n",
    "    world.run(total_runs=3, policy='PEXPLOIT', animate=True)\n",
    "    world.summary()\n",
    "    world.display_q_table(agent='male')\n",
    "    \n",
    "    world.setup(pickup_locations = [(1,2), (4,5)])\n",
    "    world.run(total_runs=3, policy='PEXPLOIT', animate=True)\n",
    "    world.summary()\n",
    "    world.display_q_table(agent='male')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q-Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QTable:\n",
    "    def __init__(self):\n",
    "        self.q_table = np.zeros((world.size**4 * 128, 6))\n",
    "        self.__operator_dict = {'n':0, 's':1, 'e':2, 'w':3, 'p':4, 'd':5}\n",
    "    \n",
    "    def next_operator(self, current_state: State, applicable_operators: list[str], policy: str ='PRANDOM') -> str:\n",
    "        \"\"\"Returns the next operator to be applied given the current state, method, and policy as a string.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        current_state: State\n",
    "            Named tuple containg state information.\n",
    "            - i: row index of agent\n",
    "            - j: column index of agent\n",
    "            - x: 1 if agent is carrying a block\n",
    "            - i_distance: distance between the agents' i values\n",
    "            - j_distance: distance between the agents' j values\n",
    "            - a: 1 if pickup location 1 has blocks left\n",
    "            - b: 1 if pickup location 2 has blocks left\n",
    "            - c: 1 if dropoff location 1 has capacity left\n",
    "            - d: 1 if dropoff location 2 has capacity left\n",
    "            - e: 1 if dropoff location 3 has capacity left\n",
    "            - f: 1 if dropoff location 4 has capacity left\n",
    "\n",
    "        applicable_operators: list\n",
    "            List of applicable operators in the current state\n",
    "        \n",
    "        policy: ['PRANDOM' | 'PEXPLOIT' | 'PGREEDY']\n",
    "            Policy to use when selecting next operator\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "            String corresponding to operator to apply:\n",
    "            ['n' | 's' | 'e' | 'w' | 'p' | 'd']\n",
    "        \"\"\"\n",
    "        assert policy in ['PRANDOM', 'PEXPLOIT', 'PGREEDY'], 'Error: Invalid policy'\n",
    "        next_operator = self.__next_operator(current_state, applicable_operators, policy)\n",
    "        return ['n', 's', 'e', 'w', 'p', 'd'][next_operator]\n",
    "\n",
    "    def update_q_table(self, previous_state: State, operator: str, current_state: State, applicable_operators: list[str], policy: str = 'PRANDOM', method: str = 'QL'):\n",
    "        \"\"\"Updates the Q-table values for the previous state and action used using the given policy and method.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        previous_state: State\n",
    "            Named tuple containg previous state information.\n",
    "            - i: row index of agent\n",
    "            - j: column index of agent\n",
    "            - x: 1 if agent is carrying a block\n",
    "            - i_distance: distance between the agents' i values\n",
    "            - j_distance: distance between the agents' j values\n",
    "            - a: 1 if pickup location 1 has blocks left\n",
    "            - b: 1 if pickup location 2 has blocks left\n",
    "            - c: 1 if dropoff location 1 has capacity left\n",
    "            - d: 1 if dropoff location 2 has capacity left\n",
    "            - e: 1 if dropoff location 3 has capacity left\n",
    "            - f: 1 if dropoff location 4 has capacity left\n",
    "\n",
    "        operator: ['n' | 's' | 'e' | 'w' | 'p' | 'd']\n",
    "            Operator that was used from previous state to current state\n",
    "\n",
    "        current_state: State\n",
    "            Named tuple containg current state information.\n",
    "\n",
    "        applicable_operators: list\n",
    "            List of applicable operators in the current state\n",
    "\n",
    "        policy: ['PRANDOM' | 'PEXPLOIT' | 'PGREEDY']\n",
    "            Policy to use when selecting next operator (used only in SARSA)\n",
    "        \n",
    "        method: ['QL' | 'SARSA']\n",
    "            Method to use when updating Q-table\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            None\n",
    "        \"\"\"\n",
    "        assert method in ['QL', 'SARSA']\n",
    "        \n",
    "        action = self.__operator_dict[operator]\n",
    "        if method == 'SARSA':\n",
    "            self.q_table[self.__encode_state(previous_state), action] = (\n",
    "                self.q_table[self.__encode_state(previous_state), action] +\n",
    "                world.alpha * (world.reward((previous_state.i, previous_state.j), operator) +\n",
    "                world.gamma * self.q_table[self.__encode_state(current_state), self.__next_operator(current_state, policy)] -\n",
    "                self.q_table[self.__encode_state(previous_state), action])\n",
    "            )\n",
    "        elif method == 'QL':\n",
    "            self.q_table[self.__encode_state(previous_state), action] = (\n",
    "                (1 - world.alpha) * self.q_table[self.__encode_state(previous_state), action] + \n",
    "                world.alpha * (world.reward((current_state.i, current_state.j), operator) + \n",
    "                world.gamma * max(self.q_table[self.__encode_state(current_state)][[self.__operator_dict[operator] for operator in applicable_operators]]))\n",
    "            )\n",
    "\n",
    "    def __next_operator(self, current_state: State, applicable_operators: list[str], policy: str ='PRANDOM') -> int:\n",
    "        \"\"\"Returns the next operator to be applied given the current state and policy as an index\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        current_state: State\n",
    "            Named tuple containg state information.\n",
    "\n",
    "        applicable_operators: list\n",
    "            List of applicable operators in the current state\n",
    "\n",
    "        policy: ['PRANDOM' | 'PEXPLOIT' | 'PGREEDY']\n",
    "            Policy to use when selecting next operator\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "            Column index of q-table corresponding to the operator to take\n",
    "            - 0: north\n",
    "            - 1: south\n",
    "            - 2: east\n",
    "            - 3: west\n",
    "            - 4: pick up\n",
    "            - 5: drop off\n",
    "        \"\"\"\n",
    "        applicable_operators_as_indices = [self.__operator_dict[operator] for operator in applicable_operators]\n",
    "        if 4 in applicable_operators_as_indices:\n",
    "            return 4\n",
    "        if 5 in applicable_operators_as_indices:\n",
    "            return 5\n",
    "        else:\n",
    "            max_val_operators = np.flatnonzero(self.q_table[self.__encode_state(current_state)] == np.max(self.q_table[self.__encode_state(current_state)]))\n",
    "            if policy == 'PRANDOM':\n",
    "                # select applicable operator randomly\n",
    "                return np.random.choice(applicable_operators_as_indices)\n",
    "            elif policy == 'PEXPLOIT':\n",
    "                if np.random.rand() < 0.8:\n",
    "                    # select applicable operator with highest q-value\n",
    "                    return np.random.choice(max_val_operators)\n",
    "                else:\n",
    "                    # select applicable operator randomly from operators without highest q-value\n",
    "                    return np.random.choice(np.setdiff1d(applicable_operators_as_indices, max_val_operators))\n",
    "            elif policy == 'PGREEDY':\n",
    "                # select applicable operator with highest q-value\n",
    "                return np.random.choice(max_val_operators)\n",
    "\n",
    "    def __encode_state(state: State) -> int:\n",
    "        \"\"\"Encodes the given state into its row index in the Q-table\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        state : State\n",
    "            Named tuple containing state information\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            integer index of state in Q-table\n",
    "        \"\"\"\n",
    "        multipliers = np.array([world.size**3 * 128, world.size**2 * 128, world.size**2 * 64, world.size * 64, 64, 32, 16, 8, 4, 2, 1])\n",
    "        return np.sum(np.multiply(np.array(state), multipliers))\n",
    "    \n",
    "    def __decode_index(index: int) -> State:\n",
    "        \"\"\"Decodes the given row index of the Q-table into a State named tuple\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        index : int\n",
    "            Row index of the Q-table\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "            Named tuple containing state information\n",
    "        \"\"\"\n",
    "        state_values = []\n",
    "        divisors = [world.size**3 * 128, world.size**2 * 128, world.size**2 * 64, world.size * 64, 64, 32, 16, 8, 4, 2, 1]\n",
    "        remainder = index\n",
    "        for divisor in divisors:\n",
    "            state_values.append(remainder // divisor)\n",
    "            remainder = remainder % divisor\n",
    "        return State(*state_values)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cef9e06bb236b2a8629b07e87a04b187b952a0f661eff5533360a155783f0c33"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
